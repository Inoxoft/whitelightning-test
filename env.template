# ONNX Model Tester Environment Configuration
# ============================================

# OpenRouter API Configuration (Required for LLM text generation)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Docker Registry Configuration (For remote deployments)
DOCKER_REGISTRY=your-registry.com
# Examples:
# DOCKER_REGISTRY=docker.io/yourusername
# DOCKER_REGISTRY=gcr.io/your-project
# DOCKER_REGISTRY=your-private-registry.com

# Remote Server Configuration
REMOTE_HOST=your-server.com
REMOTE_USER=ubuntu
# Examples:
# REMOTE_HOST=192.168.1.100
# REMOTE_HOST=my-server.example.com
# REMOTE_USER=root

# Image Version (Optional, defaults to 'latest')
VERSION=latest

# Application Configuration
ENVIRONMENT=development
# Options: development, production

# Model Testing Configuration
DEFAULT_MODEL_PATH=/app/models
DEFAULT_OUTPUT_PATH=/app/outputs

# Logging Configuration
LOG_LEVEL=INFO
# Options: DEBUG, INFO, WARNING, ERROR

# Performance Configuration
MAX_WORKERS=4
TIMEOUT_SECONDS=300

# Cache Configuration (Optional - for Redis)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0 