<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TF-IDF Preprocessing Bug Analysis</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            color: #333;
        }
        
        .header {
            text-align: center;
            border-bottom: 3px solid #2c3e50;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        
        .header h1 {
            color: #2c3e50;
            font-size: 2.2em;
            margin-bottom: 10px;
        }
        
        .header .subtitle {
            color: #7f8c8d;
            font-size: 1.1em;
            font-style: italic;
        }
        
        .section {
            margin-bottom: 30px;
            padding: 20px;
            border-left: 4px solid #3498db;
            background-color: #f8f9fa;
        }
        
        .section h2 {
            color: #2c3e50;
            border-bottom: 2px solid #ecf0f1;
            padding-bottom: 10px;
            margin-top: 0;
        }
        
        .section h3 {
            color: #34495e;
            margin-top: 25px;
        }
        
        .code-block {
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
            margin: 15px 0;
        }
        
        .python-correct {
            border-left: 4px solid #27ae60;
            background-color: #d5f4e6;
        }
        
        .c-incorrect {
            border-left: 4px solid #e74c3c;
            background-color: #fadbd8;
        }
        
        .nodejs-incorrect {
            border-left: 4px solid #f39c12;
            background-color: #fdeaa7;
        }
        
        .results-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        .results-table th,
        .results-table td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        
        .results-table th {
            background-color: #34495e;
            color: white;
        }
        
        .results-table tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        
        .highlight {
            background-color: #fff3cd;
            padding: 2px 4px;
            border-radius: 3px;
            font-weight: bold;
        }
        
        .correct {
            color: #27ae60;
            font-weight: bold;
        }
        
        .incorrect {
            color: #e74c3c;
            font-weight: bold;
        }
        
        .formula {
            background-color: #e8f4f8;
            padding: 15px;
            border: 1px solid #3498db;
            border-radius: 5px;
            text-align: center;
            font-family: 'Times New Roman', serif;
            font-size: 1.1em;
            margin: 15px 0;
        }
        
        .step {
            margin: 15px 0;
            padding: 10px;
            border-left: 3px solid #3498db;
            background-color: #f8f9fa;
        }
        
        .emoji {
            font-size: 1.2em;
        }
        
        .fix-section {
            background-color: #d5f4e6;
            border-left: 4px solid #27ae60;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üêõ TF-IDF Preprocessing Bug Analysis</h1>
        <div class="subtitle">Why Python and C/Node.js Give Different Results in Binary Classification</div>
        <div style="margin-top: 15px; color: #7f8c8d;">
            <strong>Date:</strong> December 2024 &nbsp;|&nbsp; 
            <strong>Issue:</strong> Mathematical Preprocessing Error
        </div>
    </div>

    <div class="section">
        <h2>üéØ Executive Summary</h2>
        <p>The binary classifier implementations in different programming languages are producing <strong>opposite results</strong> for the same input text. The issue is <strong>NOT</strong> in the ONNX model itself, but in the <strong>mathematical preprocessing</strong> of text data before feeding it to the model.</p>
        
        <table class="results-table">
            <thead>
                <tr>
                    <th>Language</th>
                    <th>Input Text</th>
                    <th>Predicted Sentiment</th>
                    <th>Confidence</th>
                    <th>Status</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td><strong>Python</strong></td>
                    <td>"It was very bad purchase"</td>
                    <td class="correct">NEGATIVE üòû</td>
                    <td class="correct">1.71%</td>
                    <td class="correct">‚úÖ CORRECT</td>
                </tr>
                <tr>
                    <td><strong>Node.js</strong></td>
                    <td>"It was very bad purchase"</td>
                    <td class="incorrect">POSITIVE üòä</td>
                    <td class="incorrect">99.95%</td>
                    <td class="incorrect">‚ùå WRONG</td>
                </tr>
                <tr>
                    <td><strong>C</strong></td>
                    <td>"It was very bad purchase"</td>
                    <td class="incorrect">POSITIVE üòä</td>
                    <td class="incorrect">~99%</td>
                    <td class="incorrect">‚ùå WRONG</td>
                </tr>
            </tbody>
        </table>
    </div>

    <div class="section">
        <h2>üßÆ The TF-IDF Algorithm</h2>
        <p>TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that reflects how important a word is to a document. The correct formula is:</p>
        
        <div class="formula">
            <strong>TF-IDF = TF √ó IDF</strong><br>
            where:<br>
            <strong>TF</strong> = (word count in document) √∑ (total words in document)<br>
            <strong>IDF</strong> = pre-calculated importance weight
        </div>
        
        <p>The critical step that's being missed is the <span class="highlight">normalization of Term Frequency by total word count</span>.</p>
    </div>

    <div class="section python-correct">
        <h2>‚úÖ Python Implementation (CORRECT)</h2>
        <p>The Python implementation follows the correct TF-IDF calculation:</p>
        
        <div class="code-block">
def preprocess_text(self, text):
    # Step 1: Initialize TF vector
    tf = np.zeros(len(word2idx), dtype=np.float32)
    words = text.lower().split()
    
    # Step 2: Count word frequencies
    for word in words:
        idx = word2idx.get(word)
        if idx is not None:
            tf[idx] += 1
    
    # Step 3: NORMALIZE by total word count (CRITICAL!)
    if tf.sum() > 0:
        tf = tf / tf.sum()  # This makes it proper Term Frequency
    
    # Step 4: Calculate TF-IDF
    tfidf = tf * np.array(idf, dtype=np.float32)
    
    # Step 5: Apply standardization
    tfidf_scaled = (tfidf - mean) / scale
    return tfidf_scaled
        </div>
        
        <h3>What Python Does Right:</h3>
        <div class="step">
            <strong>Step 1:</strong> Counts word frequencies correctly
        </div>
        <div class="step">
            <strong>Step 2:</strong> <span class="correct">Normalizes TF by total word count</span>
        </div>
        <div class="step">
            <strong>Step 3:</strong> Multiplies TF √ó IDF to get proper TF-IDF
        </div>
        <div class="step">
            <strong>Step 4:</strong> Applies StandardScaler normalization
        </div>
    </div>

    <div class="section c-incorrect">
        <h2>‚ùå C Implementation (INCORRECT)</h2>
        <p>The C implementation skips the critical TF normalization step:</p>
        
        <div class="code-block">
// Process text - INCORRECT IMPLEMENTATION
char* word = strtok(text_copy, " \t\n");
while (word) {
    cJSON* idx = cJSON_GetObjectItem(vocab, word);
    if (idx) {
        int i = idx->valueint;
        if (i < 5000) {
            cJSON* idf_item = cJSON_GetArrayItem(idf, i);
            if (idf_item) {
                // ‚ùå WRONG: Just adding IDF values directly!
                vector[i] += idf_item->valuedouble;  
            }
        }
    }
    word = strtok(NULL, " \t\n");
}
// ‚ùå MISSING: No TF normalization step!
        </div>
        
        <h3>What C Does Wrong:</h3>
        <div class="step">
            <strong>Problem 1:</strong> <span class="incorrect">No TF calculation</span> - skips term frequency entirely
        </div>
        <div class="step">
            <strong>Problem 2:</strong> <span class="incorrect">Uses raw IDF values</span> instead of TF-IDF
        </div>
        <div class="step">
            <strong>Problem 3:</strong> <span class="incorrect">Missing normalization</span> by total word count
        </div>
        <div class="step">
            <strong>Result:</strong> Feature vectors are 4√ó larger than they should be!
        </div>
    </div>

    <div class="section nodejs-incorrect">
        <h2>‚ùå Node.js Implementation (INCORRECT)</h2>
        <p>The Node.js implementation has the same fundamental error as C:</p>
        
        <div class="code-block">
// Apply TF-IDF - INCORRECT IMPLEMENTATION
for (const [word, count] of Object.entries(wordCounts)) {
    if (vocab.hasOwnProperty(word)) {
        const idx = vocab[word];
        if (idx < 5000) {
            // ‚ùå WRONG: Using raw word count instead of normalized TF!
            vector[idx] = count * idf[idx];  
        }
    }
}
// ‚ùå MISSING: No TF normalization by total word count!
        </div>
        
        <h3>What Node.js Does Wrong:</h3>
        <div class="step">
            <strong>Problem 1:</strong> <span class="incorrect">Uses raw word counts</span> instead of normalized TF
        </div>
        <div class="step">
            <strong>Problem 2:</strong> <span class="incorrect">No division by total words</span>
        </div>
        <div class="step">
            <strong>Problem 3:</strong> <span class="incorrect">Same mathematical error as C</span>
        </div>
        <div class="step">
            <strong>Result:</strong> Massively inflated feature values leading to wrong predictions!
        </div>
    </div>

    <div class="section">
        <h2>üîç Mathematical Example</h2>
        <p>Let's trace through the calculation for <strong>"It was bad purchase"</strong> (4 words):</p>
        
        <h3>Python (Correct Calculation):</h3>
        <div class="step">
            <strong>Step 1:</strong> Count frequencies - "it":1, "was":1, "bad":1, "purchase":1, Total=4
        </div>
        <div class="step">
            <strong>Step 2:</strong> Calculate TF (normalized) - tf["bad"] = 1/4 = 0.25
        </div>
        <div class="step">
            <strong>Step 3:</strong> TF-IDF calculation - tfidf["bad"] = 0.25 √ó 6.2 = 1.55
        </div>
        <div class="step">
            <strong>Step 4:</strong> After standardization - Features properly scaled
        </div>
        <div class="step">
            <strong>Result:</strong> <span class="correct">NEGATIVE sentiment (1.7% = very negative) ‚úÖ</span>
        </div>
        
        <h3>C/Node.js (Wrong Calculation):</h3>
        <div class="step">
            <strong>Step 1:</strong> Count frequencies - "bad":1 occurrence
        </div>
        <div class="step">
            <strong>Step 2:</strong> <span class="incorrect">NO TF normalization!</span> - Just use raw count = 1
        </div>
        <div class="step">
            <strong>Step 3:</strong> Wrong calculation - vector["bad"] = 1 √ó 6.2 = 6.2 (4√ó too large!)
        </div>
        <div class="step">
            <strong>Step 4:</strong> After standardization - Features massively inflated
        </div>
        <div class="step">
            <strong>Result:</strong> <span class="incorrect">POSITIVE sentiment (99.95%) ‚ùå WRONG!</span>
        </div>
    </div>

    <div class="fix-section">
        <h2>üõ†Ô∏è How to Fix</h2>
        
        <h3>For C Implementation:</h3>
        <div class="code-block">
// CORRECTED C implementation
float* preprocess_text(const char* text, ...) {
    float* tf = calloc(5000, sizeof(float));
    float* vector = calloc(5000, sizeof(float));
    
    // Step 1: Count word frequencies AND total words
    int total_words = 0;
    char* word = strtok(text_copy, " \t\n");
    while (word) {
        cJSON* idx = cJSON_GetObjectItem(vocab, word);
        if (idx) {
            int i = idx->valueint;
            if (i < 5000) {
                tf[i] += 1.0;  // Count frequency
                total_words++;  // Count total words
            }
        }
        word = strtok(NULL, " \t\n");
    }
    
    // Step 2: Calculate proper TF-IDF with normalization
    if (total_words > 0) {
        for (int i = 0; i < 5000; i++) {
            if (tf[i] > 0) {
                float normalized_tf = tf[i] / total_words;  // Proper TF
                vector[i] = normalized_tf * idf[i];         // Correct TF-IDF
            }
        }
    }
    
    // Step 3: Apply scaling as before...
    free(tf);
    return vector;
}
        </div>
        
        <h3>For Node.js Implementation:</h3>
        <div class="code-block">
// CORRECTED Node.js implementation
async function preprocessText(text) {
    const vector = new Float32Array(5000);
    
    // Load data as before...
    const words = text.toLowerCase().split(/\s+/);
    const totalWords = words.length;  // Get total word count
    const wordCounts = {};
    
    // Count word frequencies
    for (const word of words) {
        wordCounts[word] = (wordCounts[word] || 0) + 1;
    }
    
    // Apply proper TF-IDF with normalization
    for (const [word, count] of Object.entries(wordCounts)) {
        if (vocab.hasOwnProperty(word)) {
            const idx = vocab[word];
            if (idx < 5000) {
                const tf = count / totalWords;     // Proper TF normalization
                vector[idx] = tf * idf[idx];       // Correct TF-IDF
            }
        }
    }
    
    // Apply scaling as before...
    return vector;
}
        </div>
    </div>

    <div class="section">
        <h2>üìä Conclusion</h2>
        <p>This bug demonstrates the critical importance of <strong>mathematical consistency</strong> across different implementations. The ONNX model itself is working correctly, but incorrect preprocessing in C and Node.js implementations was causing:</p>
        
        <ul>
            <li><span class="incorrect">‚ùå Opposite sentiment predictions</span></li>
            <li><span class="incorrect">‚ùå False high confidence scores</span></li>
            <li><span class="incorrect">‚ùå Inconsistent results across languages</span></li>
            <li><span class="incorrect">‚ùå Loss of model reliability</span></li>
        </ul>
        
        <p>The fix is straightforward but critical: <strong>normalize term frequencies by total word count</strong> before multiplying by IDF values. This single change will align all implementations and restore prediction accuracy.</p>
        
        <div style="margin-top: 30px; padding: 15px; background-color: #e8f4f8; border-radius: 5px; text-align: center;">
            <strong>Key Takeaway:</strong> Always verify mathematical consistency when porting ML preprocessing across programming languages. Small differences in numerical calculations can lead to dramatically different results.
        </div>
    </div>

    <div style="margin-top: 40px; text-align: center; color: #7f8c8d; border-top: 1px solid #ecf0f1; padding-top: 20px;">
        <p><strong>Bug Analysis Report</strong> | Generated December 2024</p>
        <p>TF-IDF Preprocessing Implementation Consistency Issue</p>
    </div>
</body>
</html> 